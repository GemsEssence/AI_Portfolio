# Visionary Hub ğŸš€

**Visionary Hub** is a professional-level **object detection web application** built using **FastAPI** and **YOLOv8**.  
It allows users to detect objects from **uploaded images** or **real-time camera input** and provides structured insights about detected objects.

---

## ğŸ“‚ Project Structure

```bash
visionary_hub/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py           # FastAPI app with routes & template rendering
â”‚   â”œâ”€â”€ settings.py               # Configuration and device selection
â”‚   â”œâ”€â”€ vision/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ visionary.py          # YOLO model handling & inference
â”‚   â”œâ”€â”€ narratives/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ request_schemas.py    # Input validation
â”‚   â”‚   â””â”€â”€ response_schemas.py   # Response structure & validation
â”‚   â”œâ”€â”€ insights/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ object_insights.py    # Map objects to descriptions & questions
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ image_reader.py       # Image preprocessing utility
â”‚   â”‚   â””â”€â”€ logger.py             # Logging setup
â”‚   â”œâ”€â”€ static/                   # Frontend assets
â”‚   â”‚   â”œâ”€â”€ styles.css
â”‚   â”‚   â””â”€â”€ scripts.js
â”‚   â””â”€â”€ templates/                # HTML templates
â”‚       â””â”€â”€ index.html
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ artifacts/
â”‚   â”‚   â””â”€â”€ yolov8n.pt            # Pre-trained YOLO model
â”‚   â””â”€â”€ mappings/
â”‚       â””â”€â”€ object_map.json       # Object descriptions & follow-up questions
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_app.py               # Optional unit tests
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # Project overview & setup instructions

ğŸ”§ Features

    - Detect objects from uploaded images or real-time camera feed.

    - Retrieve structured information for each detected object:

    - Description

    - Usage

    - Benefits

    - Origin

    - Summary

    - Suggest follow-up questions for each detected object.

    Minimal frontend for interaction with FastAPI backend.

âš™ï¸ Setup Instructions
1. Clone the repository
git clone <your-repo-url>
cd visionary_hub

2. Create and activate a Python virtual environment
python -m venv venv
source venv/bin/activate      # Linux / macOS
venv\Scripts\activate         # Windows

3. Install dependencies
pip install -r requirements.txt

4. Setup environment variables

Create a .env file in the root directory:

DEBUG=True

5. Download YOLO model

Place the pre-trained YOLO model yolov8n.pt in:

data/artifacts/

6. Run the application locally
uvicorn app.orchestrator:app --reload

7. Open in browser

    - Visit: http://127.0.0.1:8000

    - Upload Image: Upload any image to detect objects.

   -  Use Camera: Detect objects in real-time using your webcam.

ğŸ“ Notes

    - app/ contains all FastAPI modules and business logic.

    - static/ & templates/ manage frontend content.

    - data/ stores models and object mappings.

    - tests/ is optional for unit tests.

    - .env handles configuration such as debug mode.

    - requirements.txt includes all Python dependencies.

âœ… Next Steps

    - Add more object mappings in object_map.json for richer insights.

    - Expand frontend features for enhanced interactivity.

    - Write unit tests in tests/ for robust development.

    - Deploy to cloud or local server for production use.

ğŸ“š References

    - YOLOv8 Documentation

    - FastAPI Documentation

    - Wikipedia Python Library


---
